{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b0b389-e3df-4e03-a004-484daf6fafce",
   "metadata": {},
   "source": [
    "# Álgebra Lineal Computacional\n",
    "## TP Red Neuronal Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357d2b61-c18c-49a9-9b34-2d75d84d2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from alc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8460017-ebc7-4352-94f5-bb88f4aec71b",
   "metadata": {},
   "source": [
    "## 1. Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938d516f-9bab-4309-8eb6-e38e7426cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"template-alumnos/dataset/cats_and_dogs\"\n",
    "\n",
    "# --- Training dataset ---\n",
    "X_cats = np.load(f'{BASE_PATH}/train/cats/efficientnet_b3_embeddings.npy')\n",
    "X_dogs = np.load(f'{BASE_PATH}/train/dogs/efficientnet_b3_embeddings.npy')\n",
    "\n",
    "X_train = np.hstack([X_cats, X_dogs])  \n",
    "\n",
    "Y_train = np.hstack([\n",
    "    np.tile([[1],[0]], (1, X_cats.shape[1])),\n",
    "    np.tile([[0],[1]], (1, X_dogs.shape[1]))\n",
    "])                                             \n",
    "\n",
    "# --- Validation dataset ---\n",
    "V_cats = np.load(f'{BASE_PATH}/val/cats/efficientnet_b3_embeddings.npy')\n",
    "V_dogs = np.load(f'{BASE_PATH}/val/dogs/efficientnet_b3_embeddings.npy')\n",
    "\n",
    "X_val = np.hstack([V_cats, V_dogs])\n",
    "Y_val = np.hstack([\n",
    "    np.tile([[1],[0]], (1, V_cats.shape[1])),\n",
    "    np.tile([[0],[1]], (1, V_dogs.shape[1]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aea3c4b-a3b8-4764-b490-ee89e2fddca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1536, 2000), Y_train: (2, 2000)\n",
      "X_val: (1536, 1000) Y_val: (2, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'X_val: {X_val.shape} Y_val: {Y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4434a16-ddae-4334-a546-7702530106a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Descomposición SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9fec3e-24ac-46c7-922c-21c7bdd9b1fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m S, D, V \u001b[38;5;241m=\u001b[39m \u001b[43msvd_reducida\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/FCEN/Álgebra Lineal Computacional/alc-2025/src/alc/alc.py:722\u001b[0m, in \u001b[0;36msvd_reducida\u001b[0;34m(A, k, atol)\u001b[0m\n\u001b[1;32m    713\u001b[0m \"\"\"\n\u001b[1;32m    714\u001b[0m A una matriz de m x n\n\u001b[1;32m    715\u001b[0m k el número de componentes singulares a calcular (por default 'max' calcula el máximo posible)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m y hatV (n x k).\n\u001b[1;32m    719\u001b[0m \"\"\"\n\u001b[1;32m    720\u001b[0m m, n = A.shape\n\u001b[0;32m--> 722\u001b[0m # Generar matriz cuadrada\n\u001b[1;32m    723\u001b[0m cuadrada = multiplicar(transpuesta(A), A)\n\u001b[1;32m    725\u001b[0m # Aplicar una diagonalización para obtener autovaloes y autovectores asociados:\n",
      "File \u001b[0;32m~/Documents/FCEN/Álgebra Lineal Computacional/alc-2025/src/alc/alc.py:685\u001b[0m, in \u001b[0;36mdiagRH\u001b[0;34m(A, atol, K)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S, D\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# Reducir el problema\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m B \u001b[38;5;241m=\u001b[39m \u001b[43mmultiplicar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultiplicar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranspuesta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHv1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHv1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m A_tilde \u001b[38;5;241m=\u001b[39m B[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# Paso recursivo\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/FCEN/Álgebra Lineal Computacional/alc-2025/src/alc/alc.py:31\u001b[0m, in \u001b[0;36mmultiplicar\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     29\u001b[0m         suma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m_B):\n\u001b[0;32m---> 31\u001b[0m             suma \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m A[i, k] \u001b[38;5;241m*\u001b[39m B[k, j]\n\u001b[1;32m     32\u001b[0m         result[i, j] \u001b[38;5;241m=\u001b[39m suma\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "S, D, V = svd_reducida(X_train, atol=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa365c-d4c9-4b7b-a924-4526ebc3ad65",
   "metadata": {},
   "source": [
    "## 4. Descomposición QR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7a135-a09d-4fb2-8288-698a3241deb1",
   "metadata": {},
   "source": [
    "Los métodos `pinvGramSchmidt` y `pinvHouseHolder` son idénticos porque el cálculo de $W$ a partir de $Q, R, Y$ no depende del tipo de factorización.\n",
    "\n",
    "Sí cabe destacar que podrían optimizarse los métodos `inversa` y `multiplicar` haciendo uso de que $R$ es matriz triangular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df919403-7767-4cb6-999e-cd571e602a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinvGramSchmidt(Q, R, Y):\n",
    "    \"\"\"\n",
    "    Recibe Q, R factores de X.T y la matriz Y.\n",
    "    Calcula X⁺ = Q (R.T)⁻¹\n",
    "    Calcula W = Y X⁺\n",
    "    \"\"\"\n",
    "    R_T = transpuesta(R)\n",
    "    R_inv = inversa(R_T)\n",
    "    W = multiplicar(Y, multiplicar(Q, R_inv))\n",
    "    return W\n",
    "\n",
    "def pinvHouseHolder(Q, R, Y):\n",
    "    \"\"\"\n",
    "    Recibe Q, R factores de X.T y la matriz Y.\n",
    "    Calcula X⁺ = Q (R.T)⁻¹\n",
    "    Calcula W = Y X⁺\n",
    "    \"\"\"\n",
    "    R_T = transpuesta(R)\n",
    "    R_inv = inversa(R_T)\n",
    "    W = multiplicar(Y, multiplicar(Q, R_inv))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe896d14-9fed-4de9-a947-f6564e6935d5",
   "metadata": {},
   "source": [
    "#### Gram Schmidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2737ba5-87d9-4bc2-8a28-c884285b0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorizamos\n",
    "Q_gs, R_gs = QR_con_GS(transpuesta(X_train))\n",
    "\n",
    "# Guardamos matrices\n",
    "np.save('Q_gs.npy', Q_gs)\n",
    "np.save('R_gs.npy', R_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a96fe892-09db-4fc3-8a76-71211f1d0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_gs = np.load('Q_gs.npy')\n",
    "R_gs = np.load('R_gs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a2e309e-b7d2-43e0-a482-e8a0693799f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_gs: (2000, 1536), R_gs: (2000, 1536)\n"
     ]
    }
   ],
   "source": [
    "print(f'Q_gs: {Q_gs.shape}, R_gs: {R_gs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2347e4-530e-48e1-9fb7-0d599fdfe84c",
   "metadata": {},
   "source": [
    "Recortamos $R_{gs}$ para reducir su tamaño a una cuadrada (**las filas inferiores de la matriz R son nulas** como resultado de la factorización)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "124f48cd-f018-47ff-be2d-035871876487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las filas inferiores son nulas\n",
    "assert np.allclose(R_gs[1536:, :], 0, atol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70e8be3e-0ea9-4eeb-b0b3-6990244567f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_gs: (2000, 1536), R_gs: (1536, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Recortamos la matriz R\n",
    "R_gs = R_gs[:1536, :]\n",
    "print(f'Q_gs: {Q_gs.shape}, R_gs: {R_gs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c586c58-be61-4cba-82ef-fb305737e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_gs = pinvHouseHolder(Q_gs, R_gs, Y_train)\n",
    "np.save('W_gs.npy', Q_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78d8f724-eb87-45ef-b96f-53c4a11d9f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_gs = np.load('W_gs.npy')\n",
    "W_gs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15d985-09a1-4e86-9856-aa998e9f69c0",
   "metadata": {},
   "source": [
    "#### Householder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb4249-a63c-412c-8b54-6eaa3dafa231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorizamos\n",
    "Q_hh, R_hh = QR_con_HH(transpuesta(X_train))\n",
    "\n",
    "# Guardamos matrices\n",
    "np.save('Q_hh.npy', Q_hh)\n",
    "np.save('R_hh.npy', R_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec28c73d-5345-4b33-99b9-4c144948adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_hh = np.load('Q_hh.npy')\n",
    "R_hh = np.load('R_hh.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70cc9a7a-1c0e-426d-9852-cf43db394839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_hh: (2000, 2000), R_hh: (2000, 1536)\n"
     ]
    }
   ],
   "source": [
    "print(f'Q_hh: {Q_hh.shape}, R_hh: {R_hh.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca77bd1-d071-4804-80ca-92740dd0cd82",
   "metadata": {},
   "source": [
    "Recortamos $Q_{gs}$ y $R_{gs}$ para reducir los tamaños (las filas inferiores de la matriz R son nulas como resultado de la factorización)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f6ada9-6411-4c4c-a2bb-b3f6a8bed26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las filas inferiores son nulas\n",
    "assert np.allclose(R_gs[1536:, :], 0, atol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91cfabd8-0540-4ab3-bf96-99a22c9376dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_hh: (2000, 1536), R_hh: (1536, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Recortamos las matrices\n",
    "Q_hh = Q_hh[:, :1536]\n",
    "R_hh = R_hh[:1536, :]\n",
    "print(f'Q_hh: {Q_hh.shape}, R_hh: {R_hh.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e15fe3-e5a0-4786-9e2d-ad629826cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hh = pinvHouseHolder(Q_hh, R_hh, Y_train)\n",
    "np.save('W_hh.npy', W_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb9aaa28-9e08-4838-bfa2-4a6f02c2d1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_hh = np.load('W_hh.npy')\n",
    "W_hh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817d446-f2b0-449a-b49f-45cac67f1490",
   "metadata": {},
   "source": [
    "## 7. Síntesis final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc9e93-aab6-4b2f-8137-87fdeebe2b17",
   "metadata": {},
   "source": [
    "### Metodología QR\n",
    "\n",
    "#### Optimización\n",
    "Surgió la necesidad de optimizar los algoritmos de factorización QR.\n",
    "\n",
    "Reemplazamos la multiplicación de matrices enteras por bloques de tamaño reducido; aprovechando la lógica de filas/columnas nulas o invariantes.\n",
    "\n",
    "Medimos la mejora con un benchmark de 30 muestras de matrices 30 x 30; para el la factorización Housholder obtuvimos tiempos entre 10 a 100 veces mejores:\n",
    "\n",
    "| Algoritmo | Tiempo promedio | Mejor tiempo |\n",
    "|:---|:---:|:---:|\n",
    "| NumPy LAPACK | 0.00017 seg | 0.00013 seg |\n",
    "| Gram-Schmidt naif | 0.04047 seg | 0.03340 seg |\n",
    "| Gram-Schmidt optimizado | 0.01434 seg | 0.01184 seg |\n",
    "| Householder naif | 1.02379 seg | 0.85465 seg |\n",
    "| Householder optimizado | 0.03032 seg | 0.02463 seg |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
